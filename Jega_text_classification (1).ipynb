{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1885964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3740b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jegad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jegad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jegad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy import interp\n",
    "import os\n",
    "import string\n",
    "import docx2txt\n",
    "from docx import Document\n",
    "# Visualuzation packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "from docx import Document\n",
    "# NLP\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "from joblib import dump, load\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "# ML Model packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import label_binarize, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a5d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-docx\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f09ae9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: BBC_Business1.docx\n",
      "Processed file: BBC_Business10.docx\n",
      "Processed file: BBC_Business11.docx\n",
      "Processed file: BBC_Business12.docx\n",
      "Processed file: BBC_Business13.docx\n",
      "Processed file: BBC_Business14.docx\n",
      "Processed file: BBC_Business15.docx\n",
      "Processed file: BBC_Business2.docx\n",
      "Processed file: BBC_Business3.docx\n",
      "Processed file: BBC_Business4.docx\n",
      "Processed file: BBC_Business5.docx\n",
      "Processed file: BBC_Business6.docx\n",
      "Processed file: BBC_Business7.docx\n",
      "Processed file: BBC_Business8.docx\n",
      "Processed file: BBC_Business9.docx\n",
      "Processed file: BBC_Sports1.docx\n",
      "Processed file: BBC_Sports10.docx\n",
      "Processed file: BBC_Sports11.docx\n",
      "Processed file: BBC_Sports12.docx\n",
      "Processed file: BBC_Sports13.docx\n",
      "Processed file: BBC_Sports14.docx\n",
      "Processed file: BBC_Sports15.docx\n",
      "Processed file: BBC_Sports2.docx\n",
      "Processed file: BBC_Sports3.docx\n",
      "Processed file: BBC_Sports4.docx\n",
      "Processed file: BBC_Sports5.docx\n",
      "Processed file: BBC_Sports6.docx\n",
      "Processed file: BBC_Sports7.docx\n",
      "Processed file: BBC_Sports8.docx\n",
      "Processed file: BBC_Sports9.docx\n",
      "Processed file: BBC_Science1.docx\n",
      "Processed file: BBC_Science10.docx\n",
      "Processed file: BBC_Science11.docx\n",
      "Processed file: BBC_Science12.docx\n",
      "Processed file: BBC_Science13.docx\n",
      "Processed file: BBC_Science14.docx\n",
      "Processed file: BBC_Science15.docx\n",
      "Processed file: BBC_Science2.docx\n",
      "Processed file: BBC_Science3.docx\n",
      "Processed file: BBC_Science4.docx\n",
      "Processed file: BBC_Science5.docx\n",
      "Processed file: BBC_Science6.docx\n",
      "Processed file: BBC_Science7.docx\n",
      "Processed file: BBC_Science8.docx\n",
      "Processed file: BBC_Science9.docx\n",
      "       Class                                               Text\n",
      "0   business  Mattel is doubling down on its plans to expand...\n",
      "1   business  Wildfires have swept across the Greek island o...\n",
      "2   business  Chipmaking giant Taiwan Semiconductor (TSMC) h...\n",
      "3     sports  The Lionesses have been \"itching to begin\" the...\n",
      "4     sports  Mark Wood struck crucial late blows in England...\n",
      "5     sports  Manchester United have rejected a £20m bid fro...\n",
      "6    science  The Gulf Stream system of warm ocean currents ...\n",
      "7    science  The heatwaves battering Europe and the US in J...\n",
      "8    science  It's taken just shy of 20 years but Sir Richar...\n",
      "9   business  Virgin Money will close 39 of its UK banks as ...\n",
      "10  business  Banking boss Dame Alison Rose has apologised t...\n",
      "11  business  The European Central Bank (ECB) has raised int...\n",
      "12   science  False claims suggesting that the BBC has been ...\n",
      "13   science  The record-breaking UK heat experienced in 202...\n",
      "14   science  Final commands were sent to Europe's Aeolus sa...\n",
      "(15, 2)\n"
     ]
    }
   ],
   "source": [
    "def read_files_into_dataframe(file_directory, file_category):\n",
    "    news_path = 'news_dataf.csv' \n",
    "    if not os.path.exists(news_path):\n",
    "        news_dataf = pd.DataFrame(columns=[\"Class\", \"Text\"])\n",
    "    else:\n",
    "        news_dataf = pd.read_csv(news_path, index_col=0)\n",
    "\n",
    "    for name_of_file in os.listdir(file_directory):\n",
    "        if name_of_file.startswith(\"~$\") or not name_of_file.endswith(\".docx\"):\n",
    "            continue\n",
    "\n",
    "        path_of_file = os.path.join(file_directory, name_of_file)\n",
    "        try:\n",
    "            with open(path_of_file, \"rb\") as fileObject:\n",
    "                doc = Document(fileObject)\n",
    "                doc_data = \" \".join([para.text for para in doc.paragraphs])\n",
    "        except Exception as e:\n",
    "            print(f\"Error in reading {path_of_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if doc_data not in news_dataf['Text'].values:\n",
    "            news_dataf = pd.concat([news_dataf, pd.DataFrame({\"Class\": [file_category], \"Text\": [doc_data]})], ignore_index=True)\n",
    "\n",
    "        print(f\"Processed file: {name_of_file}\")\n",
    "\n",
    "    news_dataf.to_csv(news_path, escapechar='\\\\')\n",
    "    \n",
    "# Define directories for each category\n",
    "business_dir = r'C:\\Users\\jegad\\BBC_BusinessA'\n",
    "science_dir = r'C:\\Users\\jegad\\BBC_ScienceA'\n",
    "sports_dir= r'C:\\Users\\jegad\\BBC_SportsA'\n",
    "\n",
    "# Define categories\n",
    "news_categories = ['business', 'sports', 'science']\n",
    "\n",
    "# Read files from each directory and add them to the DataFrame\n",
    "read_files_into_dataframe(business_dir, news_categories[0])\n",
    "read_files_into_dataframe(sports_dir, news_categories[1])\n",
    "read_files_into_dataframe(science_dir, news_categories[2])\n",
    "\n",
    "# Read the CSV file back into a DataFrame\n",
    "news_path = 'news_dataf.csv' \n",
    "news_dataf = pd.read_csv(news_path, index_col=0)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(news_dataf)\n",
    "print(news_dataf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5461163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class    0\n",
       "Text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "news_dataf.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a39273a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Class                                               Text  \\\n",
      "0   business  Mattel is doubling down on its plans to expand...   \n",
      "1   business  Wildfires have swept across the Greek island o...   \n",
      "2   business  Chipmaking giant Taiwan Semiconductor (TSMC) h...   \n",
      "3     sports  The Lionesses have been \"itching to begin\" the...   \n",
      "4     sports  Mark Wood struck crucial late blows in England...   \n",
      "5     sports  Manchester United have rejected a £20m bid fro...   \n",
      "6    science  The Gulf Stream system of warm ocean currents ...   \n",
      "7    science  The heatwaves battering Europe and the US in J...   \n",
      "8    science  It's taken just shy of 20 years but Sir Richar...   \n",
      "9   business  Virgin Money will close 39 of its UK banks as ...   \n",
      "10  business  Banking boss Dame Alison Rose has apologised t...   \n",
      "11  business  The European Central Bank (ECB) has raised int...   \n",
      "12   science  False claims suggesting that the BBC has been ...   \n",
      "13   science  The record-breaking UK heat experienced in 202...   \n",
      "14   science  Final commands were sent to Europe's Aeolus sa...   \n",
      "\n",
      "                                                Text2  \n",
      "0   mattel double plan expand outside toy aisle sm...  \n",
      "1   wildfire swept across greek island rhodes lead...  \n",
      "2   chipmaking giant taiwan semiconductor tsmc del...  \n",
      "3   lioness itch begin woman world cup campaign sa...  \n",
      "4   mark wood struck crucial late blow england bat...  \n",
      "5   manchester united reject £20m bid west ham eng...  \n",
      "6   gulf stream system warm ocean current could co...  \n",
      "7   heatwaves batter europe u july would virtually...  \n",
      "8   take shy 20 year sir richard branson finally b...  \n",
      "9   virgin money close 39 uk bank few people use b...  \n",
      "10  banking bos dame alison rise apologise nigel f...  \n",
      "11  european central bank ecb raise interest rate ...  \n",
      "12  false claim suggest bbc misreporting temperatu...  \n",
      "13  recordbreaking uk heat experienced 2022 regard...  \n",
      "14  final command sent europe aeolus satellite fri...  \n",
      "Wildfires have swept across the Greek island of Rhodes, leading some holidaymakers to abandon their belongings and move to makeshift shelters. Airlines and holiday companies are scrambling to bring some of those affected home, while some flights to the island from the UK have been cancelled. Up to 10,000 British tourists are there, with many more booked to travel in the coming weeks. So what are their rights? Can I still travel to Rhodes? A number of airlines are continuing flights as normal, but some have cancelled flights or package holidays scheduled for the coming days. Crucially, the official advice from the UK Foreign Office has stopped short of advising against travel to Rhodes. Instead, it is advising people to follow guidance from the Greek emergency services. Anyone planning to travel should first check with their operator, airline or hotel. That  can change so people should keep checking, wherever they are planning to travel to. What about Corfu? Around 2,400 visitors and locals have been evacuated from Corfu and there are also wildfires on Evia. Greek officials say the fires in Corfu are coming under control and are urging travellers to go ahead with their holiday plans. Travellers should still check their flights and accommodation are not affected.  Chinese-owned video streaming app TikTok says it will offer text-only posts as competition between social media giants heats up.  the new feature gives users \"another way to express themselves\". Earlier this month, TikTok launched a new music streaming service to rival platforms like Spotify and Apple Music. And on Monday, Elon Musk's Twitter ditched its famous blue bird logo and switched to a black and white X. TikTok users will now be offered three options on the app - whether to post photos, videos or text. They will also be able to customise posts by adding sound, location or Duets, which are video reactions to posts by other TikTok users. \"These features make it so your text posts are just as dynamic and interactive as any video or photo post,\" TikTok said.   TikTok, which is owned by China's ByteDance, recently launched a new music streaming service, TikTok Music, in Brazil and Indonesia. Last week, the company also rolled out a beta version of the service in Singapore, Mexico and Australia. A spokesman said it would allow users to \"listen, share and download the music they have discovered on TikTok, as well as share their favourite tracks and artists with their TikTok community\". The app is testing other features  with select users around the world. In 2021,  as it had more hits than US search engine giant Google. That year, the app also said it had more than one billion active users globally. Competition between rival social media firms - such as Instagram owner Meta and X, Mr Musk's rebranded Twitter platform - have heated up in recent weeks. This month, Meta's new Threads platform went live on Apple and Android app stores in 100 countries, including the UK. Meta boss Mark Zuckerberg later said his company's Threads platform had signed up more than 100 million users in less than five days. Also this week, the blue bird branding on social network Twitter was replaced by a logo featuring a white X on a black background. The term tweets will also be changed to \"x's\", according to Mr Musk. \n",
      "\n",
      " After Data Preprocessing\n",
      "wildfire swept across greek island rhodes lead holidaymaker abandon belonging move makeshift shelter airline holiday company scramble bring affected home flight island uk cancel 10000 british tourist many book travel come week right still travel rhodes number airline continue flight normal cancel flight package holiday schedule come day crucially official advice uk foreign office stop short advise travel rhodes instead advise people follow guidance greek emergency service anyone planning travel first check operator airline hotel change people keep check wherever planning travel corfu around 2400 visitor local evacuate corfu also wildfire evia greek official say fire corfu come control urge traveller go ahead holiday plan traveller still check flight accommodation affected chineseowned video stream app tiktok say offer textonly post competition social medium giant heat new feature give user another way express earlier month tiktok launch new music stream service rival platform like spotify apple music monday elon musk twitter ditch famous blue bird logo switch black white x tiktok user offer three option app whether post photo video text also able customise post add sound location duet video reaction post tiktok user feature make text post dynamic interactive video photo post tiktok say tiktok own china bytedance recently launch new music stream service tiktok music brazil indonesia last week company also roll beta version service singapore mexico australia spokesman say would allow user listen share download music discover tiktok well share favourite track artist tiktok community app test feature select user around world 2021 hit u search engine giant google year app also say one billion active user globally competition rival social medium firm instagram owner meta x mr musk rebranded twitter platform heat recent week month metas new thread platform go live apple android app store 100 country include uk meta bos mark zuckerberg later say company thread platform sign 100 million user less five day also week blue bird branding social network twitter replace logo feature white x black background term tweet also change x accord mr musk \n"
     ]
    }
   ],
   "source": [
    "#Preprocessing of Data\n",
    "def data_preprocess(df):\n",
    "    df['Text2'] = df['Text'].replace('\\n',' ')\n",
    "    df['Text2'] = df['Text2'].replace('\\r',' ')\n",
    "    \n",
    "    df['Text2'] = df['Text2'].str.lower()\n",
    "    df['Text2'] = df['Text2'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    stp_wrds = stopwords.words(\"english\")\n",
    "    stem_lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def postag(each):\n",
    "        p_tag = pos_tag([each])[0][1][0].upper()\n",
    "        p_hash_tag = {\"N\": wordnet.NOUN,\"R\": wordnet.ADV, \"V\": wordnet.VERB,\"J\": wordnet.ADJ}        \n",
    "        return p_hash_tag.get(p_tag, wordnet.NOUN)\n",
    "\n",
    "    \n",
    "    def lematize(text):\n",
    "        tkns = nltk.word_tokenize(text)\n",
    "        ay = \"\"\n",
    "        for each in tkns:\n",
    "            if each not in stp_wrds:\n",
    "                ay += stem_lemmatizer.lemmatize(each, postag(each)) + \" \"\n",
    "        return ay\n",
    "    \n",
    "    df['Text2'] = df['Text2'].apply(lematize)\n",
    "    \n",
    "data_preprocess(news_dataf)\n",
    "print(news_dataf)\n",
    "\n",
    "print(news_dataf.iloc[1]['Text'])\n",
    "print(\"\\n After Data Preprocessing\")\n",
    "print(news_dataf.iloc[1]['Text2'])\n",
    "\n",
    "def preprocess_of_text(txt):\n",
    "    txt = txt.replace('\\n', ' ')\n",
    "    txt = txt.replace('\\r', ' ')\n",
    "    \n",
    "    txt = txt.lower()\n",
    "    txt = txt.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    stp_wrds = set(stopwords.words(\"english\"))\n",
    "    stem_lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def postag(each):\n",
    "        tag = pos_tag([each])[0][1][0].upper()\n",
    "        hash_tag = {\"N\": wordnet.NOUN, \"R\": wordnet.ADV, \"V\": wordnet.VERB, \"J\": wordnet.ADJ}\n",
    "        return hash_tag.get(tag, wordnet.NOUN)\n",
    "\n",
    "    tkns = nltk.word_tokenize(txt)\n",
    "    txt = \" \".join(stem_lemmatizer.lemmatize(each, postag(each)) for each in tkns if each not in stp_wrds)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb6bd65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2     business\n",
      "0     business\n",
      "3       sports\n",
      "4       sports\n",
      "9     business\n",
      "1     business\n",
      "11    business\n",
      "8      science\n",
      "6      science\n",
      "5       sports\n",
      "12     science\n",
      "14     science\n",
      "Name: Class, dtype: object\n",
      "13     science\n",
      "7      science\n",
      "10    business\n",
      "Name: Class, dtype: object\n",
      "(12,) (3,) (12,) (3,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(news_dataf['Text2'], \n",
    "                                                    news_dataf['Class'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=9)\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63397e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVectorizer Configuration\n",
    "vect = TfidfVectorizer(stop_words='english', \n",
    "                         ngram_range = (1,2),\n",
    "                         min_df = 3,\n",
    "                         max_df = 1.,\n",
    "                         max_features = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76a2d8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Mean Metrics:\n",
      "test_accuracy              0.722222\n",
      "test_precision_weighted    0.611111\n",
      "test_recall_weighted       0.722222\n",
      "test_f1_weighted           0.643519\n",
      "dtype: float64\n",
      "  \n",
      "Naive Bayes Mean Metrics:\n",
      "test_accuracy              0.444444\n",
      "test_precision_weighted    0.259259\n",
      "test_recall_weighted       0.444444\n",
      "test_f1_weighted           0.305556\n",
      "dtype: float64\n",
      "  \n",
      "Ridge Classifier Mean Metrics:\n",
      "test_accuracy              0.805556\n",
      "test_precision_weighted    0.791667\n",
      "test_recall_weighted       0.805556\n",
      "test_f1_weighted           0.768519\n",
      "dtype: float64\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Cross validation\n",
    "\n",
    "def fit_model(model, model_name):\n",
    "    fit_line = Pipeline([('vectorize', vect), (model_name, model)])\n",
    "    \n",
    "    \n",
    "    op = cross_validate(fit_line, \n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            cv = KFold(shuffle = True, \n",
    "                                       n_splits = 3,  \n",
    "                                       random_state = 9),\n",
    "                            scoring = ('accuracy', 'f1_weighted','precision_weighted','recall_weighted'),           \n",
    "                            return_train_score=True)\n",
    "    \n",
    "    return op\n",
    "#Splitting the training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(news_dataf['Text2'], \n",
    "                                                    news_dataf['Class'], \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=9)\n",
    "\n",
    "randforest = fit_model(RandomForestClassifier(), 'RF')\n",
    "ridge = fit_model(RidgeClassifier(), 'Ridge')\n",
    "bayes = fit_model(MultinomialNB(), 'NB')\n",
    "\n",
    "rf = pd.DataFrame.from_dict(randforest)\n",
    "rc = pd.DataFrame.from_dict(ridge)\n",
    "bc = pd.DataFrame.from_dict(bayes)\n",
    "\n",
    "l1 = [bc, rc, rf]\n",
    "l2 =[\"NB\", \"Ridge\", \"RF\"]\n",
    "\n",
    "for each, tag in zip(l1, l2):\n",
    "    each['model'] = [tag, tag, tag]\n",
    "\n",
    "joined_output = pd.concat([bc,rc,rf])\n",
    "\n",
    "relevant_measures = list(['test_accuracy','test_precision_weighted', 'test_recall_weighted', 'test_f1_weighted'])\n",
    "\n",
    "rand_forest_metrics = joined_output.loc[joined_output.model == 'RF'][relevant_measures]\n",
    "nb_metrics = joined_output.loc[joined_output.model == 'NB'][relevant_measures]\n",
    "r_metrics = joined_output.loc[joined_output.model == 'Ridge'][relevant_measures]\n",
    "\n",
    "metrics_ = [rand_forest_metrics, nb_metrics, r_metrics]\n",
    "names_ = ['Random Forest', 'Naive Bayes', 'Ridge Classifier']\n",
    "\n",
    "for scores, namess in zip(metrics_, names_):\n",
    "    print(f'{namess} Mean Metrics:')\n",
    "    print(scores.mean())\n",
    "    print('  ')\n",
    "    \n",
    "# Join training and test datasets\n",
    "X = pd.concat([X_train, \n",
    "               X_test])\n",
    "y = pd.concat([y_train, \n",
    "               y_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d985073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and Fit a Text Classification Model\n",
    "def create_and_fit(classf, x, y):\n",
    "    best_classf = classf\n",
    "    pipeline = Pipeline([('vectorize', vect), ('model', best_classf)])\n",
    "    return pipeline.fit(x, y)\n",
    "# Create model\n",
    "CLASSIFIER = create_and_fit(MultinomialNB(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86e49b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a news article text: Aeolus was regarded as something of a revolution. Its ultraviolet laser tracked the movement of air in all locations, at every altitude, across the world.\n",
      "Predicted class: science\n"
     ]
    }
   ],
   "source": [
    "def predict_user_input(classifier):\n",
    "    usr_input = input(\"Enter a news article text: \")\n",
    "    preprocessd_input = preprocess_of_text(usr_input)\n",
    "\n",
    "    # Use classifier to query and find the class\n",
    "    predict_class = classifier.predict([preprocessd_input])[0]\n",
    "    \n",
    "    print(f\"Predicted class: {predict_class}\")\n",
    "\n",
    "predict_user_input(CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf8afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dac4911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "from tkinter import END\n",
    "\n",
    "# Function to make a prediction\n",
    "def predict():\n",
    "    usr_input = usr_input_text.get(1.0, END).strip()\n",
    "    if not usr_input:\n",
    "        result_text.config(state=tk.NORMAL)\n",
    "        result_text.delete(1.0, END)\n",
    "        result_text.insert(tk.INSERT, \"Enter the news article to find the class:\")\n",
    "        result_text.config(state=tk.DISABLED)\n",
    "        return\n",
    "\n",
    "    preprocessd_input = preprocess_of_text(usr_input)\n",
    "    predict_class = CLASSIFIER.predict([preprocessd_input])[0]\n",
    "\n",
    "    result_text.config(state=tk.NORMAL)\n",
    "    result_text.delete(1.0, END)\n",
    "    result_text.insert(tk.INSERT, f\"Predicted class: {predict_class}\")\n",
    "    result_text.config(state=tk.DISABLED)\n",
    "\n",
    "# Create the Tkinter application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Text Classifier GUI\")\n",
    "\n",
    "# Create a label and input text box for the user input\n",
    "usr_input_label = tk.Label(root, text=\"Enter a news article text:\")\n",
    "usr_input_label.pack()\n",
    "usr_input_text = scrolledtext.ScrolledText(root, width=40, height=5, wrap=tk.WORD)\n",
    "usr_input_text.pack()\n",
    "\n",
    "# Create a button to trigger prediction\n",
    "predict_button = tk.Button(root, text=\"Predict\", command=predict)\n",
    "predict_button.pack()\n",
    "\n",
    "# Create a text widget to display the prediction result\n",
    "result_text = scrolledtext.ScrolledText(root, width=40, height=3, wrap=tk.WORD, state=tk.DISABLED)\n",
    "result_text.pack()\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56963334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37570d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
